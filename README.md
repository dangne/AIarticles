## Natural Language Processing

- [Neural Machine Translation By Jointly Learning To Align And Translate](https://arxiv.org/pdf/1409.0473.pdf)
- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
- [Reformer: The Efficient Transformer](https://arxiv.org/pdf/2001.04451.pdf)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)
- [PhoBERT: Pre-trained language models for Vietnamese](https://arxiv.org/pdf/2003.00744.pdf)
- [Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
- [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)



## Computer Vision

- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/pdf/1905.11946.pdf)
- [Facial Expression Recognition via a Boosted Deep Belief Network](http://openaccess.thecvf.com/content_cvpr_2014/papers/Liu_Facial_Expression_Recognition_2014_CVPR_paper.pdf)
- [Self-training with Noisy Student improves ImageNet classification](https://arxiv.org/pdf/1911.04252.pdf)


## Generative Models

- [Generative Adversarial Nets (GAN)](https://arxiv.org/pdf/1406.2661.pdf)



## Misc

- **Regularization Methods**
  - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)

- **Weight Initialization**
  - [Xavier Initialization](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)
  - [He Initialization](https://arxiv.org/pdf/1502.01852.pdf)

- [Graph Neural Networks: A Review of Methods and Applications](https://arxiv.org/pdf/1812.08434.pdf)
- [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/pdf/1506.01186.pdf)
- [Dynamic Routing Between Capsules](https://arxiv.org/pdf/1710.09829.pdf)
- [Neural Tangents: Fast And Easy Infinite Neural Networks In Python](https://arxiv.org/pdf/1912.02803.pdf)
