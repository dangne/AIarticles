# Robustness May Be at Odds with Accuracy

- Link: https://arxiv.org/pdf/1805.12152.pdf
  - [x] First pass
  - [ ] Second pass
  - [ ] Third pass
- Key-points:
  - The goal of adversarially robust generalization might fundamentally be at odds with that of standard generalization
- It emphasizes the need to develop robust training methods, since robustness is unlikely to arise as a consequence of standard training
  - Moreover, we discover that even though adversarial robustness comes at a price, it has some unexpected benefits. Robust models learn meaningful feature representations that align well with salient data characteristics
  - We demonstrate a striking consequence of this phenomenon: robust models yield clean feature interpolations similar to those obtained from generative models such as GANs. This emphasizes the possibility of a stronger connection between
  - Finally, our findings show that the interplay between adversarial robustness and standard classification might be more nuanced that one might expect
- Dataset:
  - MNIST
  - CIFAR-10
  - Restricted ImageNet
