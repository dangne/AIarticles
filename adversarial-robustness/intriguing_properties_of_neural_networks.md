# Intriguing properties of neural networks

- Link: https://arxiv.org/pdf/1312.6199.pdf
  - [x] First pass
  - [x] Second pass
  - [ ] Third pass
- Key-points:
  - An individual hidden unit by itself does not contain semantic information but rather the entire space of activations that contain the bulk of the semantic information. (Similar to word embedding, the various directions in the representation vector space give rise to a rich semantic encoding of relations and analogies)

  - **Models are vulnerable to imperceptible perturbation**
- Dataset:
  - MNIST
